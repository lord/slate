
[Source](http://docs.bons.ai/inkling-guide-pages/4-under-the-hood "Permalink to (4) Under the Hood - Bons.ai")

## Under the Hood

This section describes some of how Bonsai AI's engine works under the hood using Inkling to teach BRAINs.

###### Major components

Bonsai's AI Engine has several major components.

* **The architect** :generates learning models using the Inkling program and characteristics of the provided training content.
* **The instructor:** trains those topologies according to the information set out in the Inkling program
* **The learner:** does the learning, and **the predictor** predicts.
* There are many other parts of our system that are more commonâ€”systems for storing and querying data, systems for streaming and manipulating data, and plumbing to expose models in the AI engine as API's

### Architect

The architect component is responsible for creating and optimizing learning topologies (e.g. neural networks) based on mental models. In essence, it takes the codified mental model and pedagogy, and it proposes a set of candidate low level learning algorithms, topologies, and their configurations that it believes will best be able to learn the concepts in the model.  This is akin to the work that the data scientist does in the toolkit approach, or that the search system automates in the statistical data analysis tools approach. Here, the system, is guided by the provided pedagogical program instead of being a broad search.

### Instructor

The instructor component is responsible for carrying out the training plan codified in the pedagogy. To do so, it must form internal representations about the capability level of each concept, and adapt the execution plan based on actual performance during training. While some operations can take place in a traditional, batch oriented fashion, the system is designed to work in an interactive streaming fashion wherein the system being trained is presented with data or an environment, asked to compute its output or action, has its performance assessed, and is then asked to learn accordingly.  This streaming approach allows intermixing data oriented and simulation oriented training approaches.

### Learner

The learner component is responsible for carrying out the actual execution of the low level, underlying artificial intelligence algorithms. In training mode, it instantiates a system conforming to what was proposed by the architect, interfaces with the instructor to set the parameters of the learning algorithm, and assess performance. Then, it executes the learning algorithm itself. In execution mode, it will instantiate an instance of the already trained system, and execute its computation when called for.

### Transformer

The transformer carries out any streaming data transformations that do not require learning. When authors create BRAIN models, some concepts do not require learning and code specifying explicitly how to calculate them can be specified. For example, if you want to use the concept of a moving average.  Rather than have the system learn how to calculate a moving average, you can easily specify how to calculate it explicitly. Such transformations take the form of "stream" statements in Inkling, which will be described in more detail below.  The transformer carries out the actual execution of such transformations when needed.

### Predictor

After an algorithm is trained, it is hosted in a 'prediction mode'. This mode holds a neural network for use as an HTTP API endpoint.  The programmer can then send input data to the predictor and get back a prediction.

## Versioning

The Bonsai AI Engine keeps versions of BRAINs. Each load operation and training session generates a new version. This way you can compare the latest version of a BRAIN with previous versions.

###### The Architect

The architect component is responsible for creating and optimizing learning topologies (e.g. neural networks) based on mental models. In this section, we outline techniques used by the architect to determine reasonable architectures.

### Heuristics

First, many heuristics regarding the mental model can be used to inform what types of artificial intelligence and machine learning algorithms to use.  For example, the data types used have a large influence. For this reason, Inkling contains rich native data types in addition to the basic data types. If the architect sees, for example, that an image is being used, a convolutional deep learning neural network architecture may be appropriate.  If the architect sees data that is temporal in nature (for example audio data, or sequence data), then a recursive deep learning neural network architecture like an LSTM network may be more appropriate. The collection of heuristics is generated by data science and machine learning / AI experts who work on the architect codebase, and who attempt to capture the heuristics that they themselves use in practice.

### Mental Model Signatures

The system also calculates a signature for a mental model. These signatures are a form of hashing such that mental models that have similar characteristics have similar signatures. These signatures can then be used in conjunction with heuristics and meta learning.

### Statistical Distribution Inference

In addition to looking at the mental model, the Architect also considers the pedagogy provided in the Inkling code.  It will, for example, look at the statistical distribution of any data sets being used; in the case of simulators, it can ask the simulator to generate substantial amounts of data so as to determine the statistics of data that will be used during training. These distribution properties can further inform the heuristics used.

### Meta Learning

Meta learning is an advanced technique used by the architect.  It is, as the name implies, learning about learning.  This means, as the architect generates candidate algorithm choices and topologies for training, it records this data along with the signature of the model and the resultant system performance.  This data set is then used in its own learning system (a portion of the architect is itself written in Inkling).  Thus the architect, by virtue of proposing, exploring, and optimizing learning models, can observe what works and what doesn't, and use that to learn what models it should try in the future when it sees similar signatures.

### Advanced Usage

For advanced users, low level details of a learning topology can be explicitly specified in part or in completely.  The architect treats any such pinning of parameters as an override on its default behavior.  In this way, specific algorithms can be provided, or a generated model can be pinned for manual refinement.

###### The Instructor

The instructor component is responsible for carrying out the training plan codified in the pedagogy.  In this section, we outline techniques used by the instructor.

### The Execution Plan

When starting a training operation, the instructor first generates an execution plan. It uses this ordering when teaching the concepts, and for each concept which lessons it intends to teach in what order. While the execution plan is executing, the instructor may jump back and forth between concepts and lessons to optimize training. The major techniques used to determine when to switch between lessons and concepts for training are reinforcement learning and adaptive learning.

###### The IDK and learning engines

The learning engine encodes the underlying detail needed to work with a particular artificial intelligence or machine learning algorithm. The BRAIN server provides many standard learning engines such as those used for deep learning. However, learning algorithm authors can provide their own backends if so desired. By architecting the BRAIN server in this way, Inkling code gains another level of abstraction from a particular approach. If a new learning algorithm is created that has superior performance to existing algorithms, all that need be added is a new backend. The architect will immediately start using the backend to build systems, and existing Inkling programs can be recompiled without modification to take advantage of the improved algorithms.
